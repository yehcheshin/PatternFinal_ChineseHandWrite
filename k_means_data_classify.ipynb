{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "root = './k_mean_data/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Denoise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_bin_table(threshold=128):\n",
    "    table = []\n",
    "    for i in range(256):\n",
    "        if i < threshold:\n",
    "            table.append(0)\n",
    "        else:\n",
    "            table.append(1)\n",
    "    return table\n",
    "\n",
    "def remove_noise_pixel(img, noise_point_list):\n",
    "    for item in noise_point_list:\n",
    "        img.putpixel((item[0], item[1]), 1)\n",
    "\n",
    "def collect_noise_point(img):\n",
    "    noise_point_list = []\n",
    "    for x in range(img.width):\n",
    "        for y in range(img.height):\n",
    "            res_9 = sum_9_region_new(img, x, y)\n",
    "            if (0 < res_9 < 3) and img.getpixel((x, y)) == 0:\n",
    "                pos = (x, y)\n",
    "                noise_point_list.append(pos)\n",
    "    return noise_point_list\n",
    "\n",
    "def sum_9_region_new(img, x, y):\n",
    "    cur_pixel = img.getpixel((x, y))\n",
    "    width = img.width\n",
    "    height = img.height\n",
    "    if cur_pixel == 1:\n",
    "        return 0\n",
    "    if y < 3:\n",
    "        return 1\n",
    "    elif y > height - 3:\n",
    "        return 1\n",
    "    else:\n",
    "        if x < 3:\n",
    "            return 1\n",
    "        elif x == width - 1:\n",
    "            return 1\n",
    "        else:\n",
    "            sum = img.getpixel((x - 1, y - 1)) \\\n",
    "                  + img.getpixel((x - 1, y)) \\\n",
    "                  + img.getpixel((x - 1, y + 1)) \\\n",
    "                  + img.getpixel((x, y - 1)) \\\n",
    "                  + cur_pixel \\\n",
    "                  + img.getpixel((x, y + 1)) \\\n",
    "                  + img.getpixel((x + 1, y - 1)) \\\n",
    "                  + img.getpixel((x + 1, y)) \\\n",
    "                  + img.getpixel((x + 1, y + 1))\n",
    "            return 9 - sum\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=90)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "label_list = {}\n",
    "\n",
    "f = open('training data dic.txt', 'r', encoding=\"utf-8\")\n",
    "for idx, line in enumerate(f.readlines()):\n",
    "    if idx == 50:\n",
    "        break\n",
    "    label_list[line[0]] = idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=64x64 at 0x18A9B824190>",
      "image/png": "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\n"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_denoise = False\n",
    "data = []\n",
    "files = []\n",
    "labels = []\n",
    "binary = None\n",
    "for idx, dir_ in enumerate(os.listdir(root)):\n",
    "    for _, file in enumerate(os.listdir(root + '/' + dir_)):\n",
    "        img_path = root + dir_ + '/' + file\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((64, 64))\n",
    "        im = np.array(img).reshape(-1)\n",
    "        if is_denoise:\n",
    "            table = get_bin_table(np.mean(im))\n",
    "            binary = img.point(table, '1')\n",
    "            noise_point_list = collect_noise_point(binary)\n",
    "            remove_noise_pixel(binary, noise_point_list)\n",
    "            im = np.array(binary).reshape(-1)\n",
    "        data.append(im)\n",
    "        files.append(img_path)\n",
    "        labels.append(label_list[file[-5:-4]])\n",
    "data = np.array(data)\n",
    "img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-912d9d44fcad>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalize data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. the normalize function expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-c2ac0b6822ab>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mnor_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtorch_nor_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnor_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch_nor_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m                           FutureWarning)\n\u001B[0;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001B[0m in \u001B[0;36mnormalize\u001B[1;34m(X, norm, axis, copy, return_norm)\u001B[0m\n\u001B[0;32m   1708\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"'%d' is not a supported axis\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1709\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1710\u001B[1;33m     X = check_array(X, accept_sparse=sparse_format, copy=copy,\n\u001B[0m\u001B[0;32m   1711\u001B[0m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001B[0;32m   1712\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0maxis\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m                           FutureWarning)\n\u001B[0;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    638\u001B[0m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    639\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mallow_nd\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 640\u001B[1;33m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001B[0m\u001B[0;32m    641\u001B[0m                              % (array.ndim, estimator_name))\n\u001B[0;32m    642\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Found array with dim 3. the normalize function expected <= 2."
     ]
    }
   ],
   "source": [
    "nor_data = preprocessing.normalize(data)\n",
    "print(nor_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dimension reduce with PCA\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'shpae'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-27-18c87f16783f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mpca\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnor_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mnor_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpca\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnor_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnor_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshpae\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'shpae'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "is_reduce_dim = False\n",
    "if is_reduce_dim:\n",
    "    pca = PCA(n_components=0.8, random_state=0)\n",
    "    pca.fit(nor_data)\n",
    "    nor_data = pca.transform(nor_data)\n",
    "    print(nor_data.shpae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split training set and validation set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 4096)\n",
      "(577, 4096)\n",
      "2304\n",
      "577\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(nor_data, labels, test_size=0.2, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(len(y_train))\n",
    "print(len(y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-nearest neighbors Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: 1 n_neighbor\n",
      "F1 score: 0.19306619758861826\n",
      "Accuracy score: 0.19410745233968804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       1.00      1.00      1.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.12      0.12      0.12        10\n",
      "weighted avg       0.20      0.20      0.20        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: 5 n_neighbor\n",
      "F1 score: 0.20071272336772938\n",
      "Accuracy score: 0.2027729636048527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       1.00      1.00      1.00         1\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.12      0.12      0.12        10\n",
      "weighted avg       0.20      0.20      0.20        10\n",
      "\n",
      "Evaluation: 9 n_neighbor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.19024794551809313\n",
      "Accuracy score: 0.1923743500866551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       1.00      1.00      1.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.13      0.13      0.13        10\n",
      "weighted avg       0.20      0.20      0.20        10\n",
      "\n",
      "Evaluation: 15 n_neighbor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.21472557242809906\n",
      "Accuracy score: 0.21490467937608318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       1.00      1.00      1.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.12      0.12      0.12        10\n",
      "weighted avg       0.20      0.20      0.20        10\n",
      "\n",
      "Evaluation: 50 n_neighbor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.17945462379818436\n",
      "Accuracy score: 0.19064124783362218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       1.00      1.00      1.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.13      0.13      0.13        10\n",
      "weighted avg       0.20      0.20      0.20        10\n",
      "\n",
      "Evaluation: 100 n_neighbor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.12462057431375549\n",
      "Accuracy score: 0.15077989601386482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       1.0\n",
      "           8       0.00      0.00      0.00       0.0\n",
      "          17       0.00      0.00      0.00       1.0\n",
      "          18       0.00      0.00      0.00       1.0\n",
      "          19       0.00      0.00      0.00       1.0\n",
      "          25       0.00      0.00      0.00       1.0\n",
      "          28       0.00      0.00      0.00       0.0\n",
      "          35       0.00      0.00      0.00       0.0\n",
      "          36       0.00      0.00      0.00       1.0\n",
      "          37       0.00      0.00      0.00       1.0\n",
      "          42       0.00      0.00      0.00       1.0\n",
      "          44       0.00      0.00      0.00       1.0\n",
      "          47       0.00      0.00      0.00       1.0\n",
      "          48       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      10.0\n",
      "   macro avg       0.00      0.00      0.00      10.0\n",
      "weighted avg       0.00      0.00      0.00      10.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = [1, 5, 9, 15, 50, 100]\n",
    "for n_neighbor in n_neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor, algorithm='auto', leaf_size=1, weights='distance')\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(\"Evaluation:\", n_neighbor, \"n_neighbor\")\n",
    "    y_pred = knn.predict(X_val)\n",
    "    knn_f1 = metrics.f1_score(y_val, y_pred, average= \"weighted\")\n",
    "    print(\"F1 score: {}\".format(knn_f1))\n",
    "    knn_accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    print(\"Accuracy score: {}\".format(knn_accuracy))\n",
    "    print(metrics.classification_report(y_val[:10],y_pred[:10]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:   50.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.203128359898142\n",
      "{'algorithm': 'auto', 'leaf_size': 1, 'n_neighbors': 9, 'weights': 'distance'}\n",
      "KNeighborsClassifier(leaf_size=1, n_neighbors=9, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors':n_neighbors, 'algorithm':['auto'], 'leaf_size': [1], 'weights':['distance']}\n",
    "knn = KNeighborsClassifier()\n",
    "gridKNN = GridSearchCV(knn, param_grid, refit=True, verbose=2, n_jobs=4)\n",
    "gridKNN.fit(X_train, y_train)\n",
    "print(gridKNN.best_score_)\n",
    "print(gridKNN.best_params_)\n",
    "print(gridKNN.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN report and analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------KNN Report---------------\n",
      "F1 score: 0.19024794551809313\n",
      "Accuracy score: 0.1923743500866551\n",
      "Confusion matrix for random 10 classes: \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n",
      "Plotting confusion matrix for random 10 classes\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEcCAYAAAAYxrniAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkvklEQVR4nO3deZicVZ328e+dsAsBNEGQAGEUdBiVrYkLI0TcwjKAIwxE0dFB4zJRBlwGRl9QfPVynFHBAcWIiAqCK06EIPoiEXBYkkBAAogMLgTQJMi+SeB+/3ieJkXTXd1VXU9VV9X94aqLqmc559dN078+y3OObBMREdFOkzodQERE9J8kn4iIaLskn4iIaLskn4iIaLskn4iIaLskn4iIaLskn4iIqEvSGZJWSrphhPOS9EVJt0q6XtJuo5WZ5BMREaM5E5hd5/y+wA7lay7w5dEKTPKJiIi6bF8K/LnOJQcB33ThSmAzSVvVKzPJJyIixmtr4PaazyvKYyNap9JwIiKirSZP2c5e80hD9/iRVcuBR2sOzbc9v6WBDZHkExHRQ7zmUdZ/0eEN3fPotf/1qO2BcVR7B7BNzefp5bERpdstIqKXCJAae43fAuBt5ay3lwP32b6r3g1p+URE9Bq1tl0h6RxgFjBV0grgBGBdANunAQuB/YBbgYeBd4xWZpJPRESvaU1r5im254xy3sA/N1Jmkk9ERE9Ry1s+VUjyiYjoNS1u+VQhySciopeIrmj5TPwIIwBJG0r6saT7JH1vHOW8RdJPWxlbp0h6laRfdzqOmGganOnWoVZSkk+0lKQ3S1oi6UFJd0m6UNLftqDoQ4DnAs+xfWizhdg+2/brWxBPpSRZ0gvqXWP7MtsvbFdM0UU0qbFXByT5RMtIOgY4Cfg0RaLYFvgSxbpP47UdcIvtNS0oq+tJSpd5jCwtn+gXkjYFTgT+2fYPbT9k+3HbP7b94fKa9SWdJOnO8nWSpPXLc7MkrZD0wXLp9rskvaM89wngeOCwskV1pKSPSzqrpv4ZZWthnfLz2yXdJukBSb+V9Jaa45fX3PdKSYvL7rzFkl5Zc26RpE9K+mVZzk8lTR3h6x+M/yM18R8saT9Jt0j6s6R/q7l+pqQrJN1bXnuKpPXKc5eWl11Xfr2H1ZT/r5L+CHx98Fh5z/PLOnYrPz9P0ipJs8bz3zW6kdLyib7yCmAD4Lw613wUeDmwC7AzMBP4WM35LYFNKRYkPBI4VdLmtk+gaE19x/bGtr9WLxBJzwK+COxrexPglcCyYa57NnBBee1zgM8DF0h6Ts1lb6Z4YG4LYD3gQ3Wq3pLie7A1RbL8KnAEsDvwKuD/SNq+vPYJ4GhgKsX37jXA+wBs71Ves3P59X6npvxnU7QC59ZWbPt/gX8FzpK0EfB14Bu2F9WJN3pRZ1Y4aFiST7TKc4DVo3SLvQU40fZK26uATwBvrTn/eHn+cdsLgQeBZsc0ngReLGlD23fZXj7MNfsDv7H9LdtrbJ8D3Az8Xc01X7d9i+1HgO9SJM6RPA58yvbjwLkUieVk2w+U9d9IkXSxvdT2lWW9vwO+Auw9hq/pBNuPlfE8je2vUjxhfhWwFUWyj36Ulk/0kbsplt6oNxbxPOD3NZ9/Xx57qowhyethYONGA7H9EHAY8B7gLkkXSHrRGOIZjKl2Kfg/NhDP3bafKN8PJoc/1Zx/ZPB+STtKOl/SHyXdT9GyG7ZLr8Yq24+Ocs1XgRcD/2X7sVGujZ6UbrfoL1cAjwEH17nmToouo0Hblsea8RCwUc3nLWtP2r7I9usoWgA3U/xSHi2ewZjqrsbbIl+miGsH21OAf6PoMKnH9U5K2phiwsfXgI+X3YrRjyapsVcnQuxIrdFzbN9HMc5xajnQvpGkdSXtK+mz5WXnAB+TNK0cuD8eOGukMkexDNhL0rblZIfjBk9Ieq6kg8qxn8couu+eHKaMhcCO5fTwdSQdBuwEnN9kTI3YBLgfeLBslb13yPk/AX/VYJknA0tsv5NiLOu0cUcZ3WfwIdO0fKJf2P4ccAzFJIJVFDsbzgN+VF7yf4ElwPXAr4BrymPN1PUz4DtlWUt5esKYVMZxJ8XWv3vzzF/u2L4bOAD4IEW34UeAA2yvbiamBn2IYjLDAxStsu8MOf9x4BvlbLh/GK0wSQcBs1n7dR4D7DY4yy/6TBdMOFCxGGlERPSCSVOme/2Z8xq659GLj1s6zs3kGpYH1SIiek0WFo2IiLbrgoVFk3wiInpJB8dxGpHkExHRa9LyiYiItkvLpzWmTp3q7bab0ekwIiJa7ve//x2rV69uYbbINtots912M/jlVUs6HUZERMvt+bIKZjin5RMREW3VJdtoJ/lERPSUdLtFREQnpNstIiLaLi2fiIhou35u+Ug6g2LF4JW2X1we+w5rd6bcDLjX9i5VxRAR0XeUMZ8zgVOAbw4esH3Y4HtJnwPuq7D+iIj+1M8tH9uXSpox3DlJAv4B2Keq+iMi+pX6OfmM4lXAn2z/ZqQLJM0F5gJss+227YorIqKrie5IPp3qGJxDsaXyiGzPtz1ge2Da1GltCisiosupiVcHtL3lI2kd4O+B3dtdd0RE71NXtHw60e32WuBm2ys6UHdERM/rhuRTWbebpHOAK4AXSloh6cjy1OGM0uUWERHNk9TQqxOqnO02Z4Tjb6+qzoiI6I6WT1Y4iIjoJR2cRNCIJJ+IiB6iTDiIiIhOSPKJiIi2S/JpkWtv+gOb7zGvpWXes/iUlpYXETFRJPlERER7ZcJBRER0Qje0fCb+pg8RETFmg7PdWvmQqaTZkn4t6VZJxw5zfltJl0i6VtL1kvYbrcwkn4iIHtPK5CNpMnAqsC+wEzBH0k5DLvsY8F3bu1KsYvOl0WJM8omI6DWtXdV6JnCr7dts/wU4FzhoyDUGppTvNwXuHK3QjPlERPQStXzMZ2vg9prPK4CXDbnm48BPJb0feBbFAtJ1Vd7ykTS57Ac8v/x8dtl3eIOkMyStW3UMERH9pIlut6mSltS85jZY5RzgTNvTgf2Ab0mqm1/a0fI5CriJtU2ys4EjyvffBt4JfLkNcURE9IUmWj6rbQ+McO4OYJuaz9PLY7WOBGYD2L5C0gbAVGDlSBVW2vKRNB3YHzh98JjthS4BV1N8IRER0QIVzHZbDOwgaXtJ61FMKFgw5Jo/AK8BkPTXwAbAqnqFVt3tdhLwEeDJoSfK7ra3Aj+pOIaIiP7SwgkHttcA84CLKHqxvmt7uaQTJR1YXvZB4F2SrqPYr+3tZQNjRJV1u0k6AFhpe6mkWcNc8iXgUtuXjXD/XKDod1x344qijIjoMa2fcIDthcDCIceOr3l/I7BnI2VWOeazJ3Bg+bDRBsAUSWfZPkLSCcA04N0j3Wx7PjAfYNJGW9TNoBERsVZfr3Bg+zjb023PoOgj/HmZeN4JvAGYY/sZ3XERETE+3bCNdiceMj0NeC5whaRlko4f7YaIiGhAax8yrURbHjK1vQhYVL7Pg60RERXqhm63JIKIiB7Sya60RiT5RET0mCSfiIhouySfiIhov4mfe5J8IiJ6TVo+LbLrX2/LL686pdNhRERMfBWscFCFrkg+ERExNgK6IPck+URE9JZMtY6IiA7ogtyT5BMR0WvS8omIiPZSWj4REdFmAiZNmvjZp/LkI2kysAS4w/YBki4DNilPbwFcbfvgquOIiOgXafkUjqLYenUKgO1XDZ6Q9APgv9sQQ0RE3+iGMZ9K9/ORNB3YHzh9mHNTgH2AH1UZQ0REXynHfBp5dULVLZ+TgI+wtput1sHAxbbvrziGiIi+UTxk2sctH0kHACttLx3hkjnAOXXunytpiaQlq1avqiTGiIje09gW2r24jfaewIGSfgecC+wj6SwASVOBmcAFI91se77tAdsD06ZOqzDMiIje0g3dbpUlH9vH2Z5uewZwOPBz20eUpw8Bzrf9aFX1R0T0q35v+dRzOHW63CIiokmZcLCW7UXAoprPs9pRb0REv+mWCQdZ4SAiosd0Qe5J8omI6DVp+URERNt1Qe5J8omI6CnZRjsiItot22hHRFM232Ney8u8Z/EpLS8zJqpsox0RER3QBbknySciotek5RMREe2VbbQjIqLdssJBRER0RJJPRES0XRfknupXtZY0WdK1ks4fcvyLkh6suv6IiH7TDVsqtKPlcxRwEzBl8ICkAWDzNtQdEdFfumTCQaUtH0nTgf2B02uOTQb+A/hIlXVHRPQjdck22lW3fE6iSDKb1BybByywfVc3DIpFRHSbbvjVWlnykXQAsNL2UkmzymPPAw4FZo3h/rnAXIBttt22qjAjInrOpC7IPlW2fPYEDpS0H7ABxZjPcuAx4Nay1bORpFttv2DozbbnA/MBdt99wBXGGRHRU7og91Q35mP7ONvTbc8ADgd+bntz21vanlEef3i4xBMREc2RWj/bTdJsSb+WdKukY0e45h8k3ShpuaRvj1ZmnvOJiOgxk1rY8ikniZ0KvA5YASyWtMD2jTXX7AAcB+xp+x5JW4xWbluSj+1FwKJhjm/cjvojIvpJiydzzQRutX1bWfa5wEHAjTXXvAs41fY9ALZXjlZo5Q+ZRkREe0mNvYCpkpbUvObWFLc1cHvN5xXlsVo7AjtK+qWkKyXNHi3GdLtFRPQQUTzr06DVtgfGUe06wA4UM5mnA5dKeonte+vdEBERPaSVYz7AHcA2NZ+nl8dqrQCusv048FtJt1Ako8UjxtjSECMiorManOk2hvGhxcAOkraXtB7F7OUFQ675EeXzm5KmUnTD3Vav0BFbPpL+Cxjx+RrbHxgt4oiIaL9WzjewvUbSPOAiYDJwhu3lkk4EltheUJ57vaQbgSeAD9u+u1659brdlrQo9phANt9jXsvLvGfxKS0vs5/l+xnjIVq/woHthcDCIceOr3lv4JjyNSYjJh/b36j9LGkj2w+POdqIiOiInljhQNIryqbUzeXnnSV9qfLIIiKiKd2wqvVYJhycBLwBuBvA9nXAXhXGFBERTWr0GZ9OtZLGNNXa9u1DsuMT1YQTERHj1SurWt8u6ZWAJa3L2p1JIyJiApr4qWdsyec9wMkUyyncSTGl7p+rDCoiIprXDRt1jpp8bK8G3tJowZI2AC4F1i/r+b7tEyRdxtqdTbcArrZ9cKPlR0TEMxVTrTsdxehGTT6S/oqi5fNyiodOrwCOHlzhtI7HgH1sP1h2110u6ULbr6op+wfAfzcdfUREPF0HZ7A1Yiyz3b4NfBfYCnge8D3gnNFucuHB8uO65eupFRMkTQH2oViWISIiWqQbZruNJflsZPtbtteUr7MotsUelaTJkpYBK4Gf2b6q5vTBwMW27x/h3rmDy3uvWr1qLNVFRARd/pyPpGdLejZwoaRjJc2QtJ2kjzBkmYWR2H7C9i4Uq6DOlPTimtNzqNOCsj3f9oDtgWlTp43pi4mI6HeDYz6NvDqh3pjPUopussHQ3l1zzhRbpo6J7XslXQLMBm4oVz2dCbyxsXAjImI03TDmU29tt+3HU7CkacDjZeLZkGL/738vTx8CnG/70fHUERERzzTxU88YVzgou8t2omasx/Y3R7ltK+AbkiZTdO991/b55bnDgc80Hm5ERNQj9cgKB5JOoNgkaCeKsZ59gcuBusnH9vXAriOcm9VgnBERMUZdkHvGNNvtEOA1wB9tvwPYGdi00qgiIqJp3TDbbSzdbo/YflLSmvLZnJU8fT/viIiYQLqh5TOW5LNE0mbAVylmwD1IscpBRERMMEK9MeZj+33l29Mk/QSYUo7nRETERNPBVQsaMWLykbRbvXO2r6kmpKjSPYtP6XQIPWXzPea1vMz8N4rx6urnfIDP1TlninXZIiJighnLTLJOq/eQ6avbGUhERIyf6P6WT0REdKGe2M8nIiK6S5JPRES0VbFHz8TPPqOOS6lwhKTjy8/bSppZfWgREdGMbthSYSyTIr4EvIJi/x2AB4BTK4soIiLGpRt2Mh1Lt9vLbO8m6VoA2/dIWm+8FZerXS8B7rB9wHjLi4iIwc3kJn6321iSz+NlojA8tU/Pky2o+yjgJmBKC8qKiIhSNzznM5YYvwicB2wh6VMU2yl8ejyVSpoO7A+cPp5yIiLimXqi28322ZKWUmyrIOBg2zeNs96TgI8Am4x0gaS5wFyAbbbddpzVRUT0B6k7FhYdy2y3bYGHgR8DC4CHymNNkXQAsNL20nrX2Z5ve8D2wLSp05qtLiKi7/REywe4gGK8RxTbaG8P/Br4mybr3BM4UNJ+ZXlTJJ1l+4gmy4uIiBo98ZCp7ZfUfi5Xu37fCJePyvZxwHFlWbOADyXxRES0Ri/Ndnsa29dIelkVwURExPh1Qe4ZPflIOqbm4yRgN+DOVlRuexGwqBVlRUQE0MFVCxoxlpZP7Yy0NRRjQD+oJpyIiBgvMfGzT93kUz5cuontD7UpnoiIGIdizKfTUYyu3jba69heI2nPdgYUERHj09XJB7iaYnxnmaQFwPeAhwZP2v5hxbFFREQTumFLhbGM+WwA3A3sw9rnfQwk+UTfu2fxKZ0OIeJpur7bjWItt2OAG1ibdAa50qgiIqI5HVy1oBH1lteZDGxcvjapeT/4ioiICWhSub7bWF+jkTRb0q8l3Srp2DrXvUmSJQ2MVma9ls9dtk8cNaqIiJgwWt3tVs56PhV4HbACWCxpge0bh1y3CcVWOVeNpdx6LZ8uaLhFRMRQLV5YdCZwq+3bbP8FOBc4aJjrPgn8O/DoWGKsl3xeM5YCIiJiIhGTGnyNYmvg9prPK8pja2ss1vzcxvYFY41yxG43238eayERETExiKYmHEyVtKTm83zb88dUnzQJ+Dzw9kYqbHhh0YiImMCaW9ttte2RJgncAWxT83l6eWzQJsCLgUXl80VbAgskHWi7NqE9TWVbfUvaRtIlkm6UtFzSUeXxj0u6Q9Ky8rVfVTFERPSjFs92WwzsIGl7SesBh1NsLAqA7ftsT7U9w/YM4EqgbuKBals+a4APllswbAIslfSz8twXbP9nhXVHRPSlJrvdRlQuszYPuIjiEZwzbC+XdCKwxPaC+iUMr7LkY/su4K7y/QOSbmLIIFVERLReqzeTs70QWDjk2PEjXDtrLGVW1u1WS9IMYFfWzv+eJ+l6SWdI2nyEe+ZKWiJpyarVq9oRZkRET2jxVOtKVJ58JG1Msf/Pv9i+H/gy8HxgF4qW0eeGu8/2fNsDtgemTZ1WdZgRET1BFL/YG3l1QqWz3SStS5F4zh5cBdv2n2rOfxU4v8oYIiL6irpjVesqZ7sJ+Bpwk+3P1xzfquayN1IsXBoRES2iBl+dUGXLZ0/grcCvJC0rj/0bMEfSLhQrY/8OeHeFMURE9JVibbeJ3/Kpcrbb5QyfVBcOcywiIlpk4qeerHAQEdFzuqDhk+QTEdFb1BUTDpJ8IiJ6yOBU64kuySciosek5dNnNt9jXsvLvGfxKS0vMyJ628RPPUk+ERG9pUseMk3yiYjoIRnziYiIjkjLJyIi2m7ip54kn4iIntMFDZ8kn4iIXlKM+Uz87FPlqtZnSFop6YaaY7tIulLSsnKjuJlV1R8R0a/6fTO5M4HZQ459FviE7V2A48vPERHRMmr4n06oclXrS8vts592GJhSvt8UuLOq+iMi+lXGfJ7pX4CLJP0nRavrlW2uPyKip/X9mM8I3gscbXsb4GiKnU6HJWluOS60ZNXqVW0LMCKiqzU43tOLYz7D+Ufgh+X77wEjTjiwPd/2gO2BaVOntSW4iIhekOTzTHcCe5fv9wF+0+b6IyJ6Xl9POJB0DjALmCppBXAC8C7gZEnrAI8Cc6uqPyKiHwmYNPGHfCqd7TZnhFO7V1VnRETQsdZMI7LCQUREj8lU64iIaLu0fCIioq36fswnIiI6oXMz2BqR5BMR0Us6+OxOI5J8Wuiexad0OoSIiC5o9yT5RET0lGLMZ+KnnySfiIgeM/FTT5JPRETv6YLsk+QTEdFjMtstIiLarguGfJJ8IiJ6TRfknuq2VJC0gaSrJV0nabmkT5THJelTkm6RdJOkD1QVQ0REX1KDrw6osuXzGLCP7QclrQtcLulC4K+BbYAX2X5S0hYVxhAR0VeKfDLx2z5Vbqlg4MHy47rlyxRbab/Z9pPldSuriiEiou90yQoHle5kKmmypGXASuBntq8Cng8cJmmJpAsl7VBlDBER/aYLet2qTT62n7C9CzAdmCnpxcD6wKO2B4CvAmcMd6+kuWWCWrJq9aoqw4yI6C0tzj6SZkv6taRbJR07zPljJN0o6XpJF0vabrQyK00+g2zfC1wCzAZWAD8sT50HvHSEe+bbHrA9MG3qtHaEGRHRA9TwP3VLkyYDpwL7AjsBcyTtNOSya4EB2y8Fvg98drQoq5ztNk3SZuX7DYHXATcDPwJeXV62N3BLVTFERPQjqbHXKGYCt9q+zfZfgHOBg2ovsH2J7YfLj1dS9HbVVeVst62Ab5RZcxLwXdvnS7ocOFvS0RQTEt5ZYQwREX2lgnGcrYHbaz6vAF5W5/ojgQtHK7TK2W7XA7sOc/xeYP+q6o2I6HuNZ5+pkpbUfJ5ve37D1UpHAAMUvVp1ZYWDiIge08RzPqvLSWDDuYPi2cxB08tjT69Tei3wUWBv24+NVmFbJhxERET7tHjMZzGwg6TtJa0HHA4seHp92hX4CnDgWJ/dTPKJiOgxrZxpbXsNMA+4CLiJYvx+uaQTJR1YXvYfwMbA9yQtk7RghOKekm63iIioy/ZCYOGQY8fXvH9to2Um+URE9JJOLlvQgCSfiIge09cLi0ZERPuJ7lhYNMknIqLHdEHuSfKJiOg5XZB9knwiInpMxnwiIqLtMuYTERFt1wW5p9ItFc6QtFLSDTXHdpZ0haRfSfqxpClV1R8R0be6YCvTKpfXOZNi87hapwPH2n4JxUZyH66w/oiIvlPkk9ZtJleVypKP7UuBPw85vCNwafn+Z8Cbqqo/IqIvNbioaKfGh9q9sOhy1u6AdyhPX6Y7IiJaoAt63dqefP4JeJ+kpcAmwF9GulDSXElLJC1ZtXpV2wKMiOh6XZB92jrbzfbNwOsBJO1InR1Ny1305gPsvvuA2xJgRETX69w4TiPa2vKRtEX570nAx4DT2ll/REQ/6OsxH0nnAFcAL5S0QtKRwBxJtwA3A3cCX6+q/oiIftRoj1un2kiVdbvZnjPCqZOrqjMiIuiKp0yzwkFERI/phjGfJJ+IiB6Ttd0iIqLtuiD3JPlERPSUDs5ga0SST0REz5n42acrks811yxdveG6+v0YLp0KrG5x9SlzYpfZDTF2U5nRftu1sjCRlk/L2J42luskLbE90Mq6U+bELrMbYuymMqM3dEHu6Y7kExERY5eWT0REtF2e82m/+Smz78rshhi7qczoBRM/9yA7C0ZHRPSKnXfd3T/9xZUN3bPlpustbff4Ya+1fCIi+lonV6puRJJPRESPyZhPRES038TPPW3fRjv6mKRvdjqGiH7QDfv5JPnUkDRZ0rslfVLSnkPOfayJ8n4o6QhJG7cuymHruWWc97c8TkkLhrx+DPz94Ocmy5xd835TSV+TdL2kb0t6bqtiHy9J8yRNLd+/QNKlku6VdJWkl3Q6vuh9fb2TadUkXSPpY5Ke38JivwLsDdwNfFHS52vO/X0T5b0MOBj4g6TvSnqjpPXGE6CkByTdX74ekPQA8PzB400W2/I4genA/cDngc+Vrwdq3jfj0zXvPwfcBfwdsJjiv13DJA1IukTSWZK2kfQzSfdJWixp1ybjfK/twWVvTga+YHsz4F9pcut4SRtLOlHS8jK+VZKulPT2JmOMnqWG/+mErk0+wObAZsAlkq6WdLSk542zzJm232z7JIpfyBuXrYL1aa51utL2IcAM4MfAu4A7JH1d0uubjPHrwI+AHWxvYnsT4A/l+ylNlllFnAPAUuCjwH22FwGP2P6F7V80WebTyrf9Mdu/t/2FMvZmfAn4LHAB8D/AV2xvChxbnmtG7VjqFrbPAyi/B5s0WebZwG3AG4BPAF8E3gq8WtKn690Y/WVwbbe0fKpzj+0P2d4W+CCwA3BN+Vfs3CbLfOqvfdtrbM8FrgN+DjTTJeWyrPttf8v2fsCLgKsofrk1XqD9AYq/ps+R9AFJkwbrGYcq4nyyTArvAD4q6RTGP8FlC0nHSPogMEV62v82zf4sr2v7QtvnFGH7+xRvLgY2aLLM70s6U9JfAedJ+hdJ20l6B/CHJsucYftM2ytsfx440PZvKL6/zbTKIzqqm5PPU2xfZvt9wNbAvwOvaLKoJbXjCmXZn6BobcxoorwHhx6wfbft02zv01yIYHsp8Nry4y9o/pfkoEriLMtZYftQ4ELgrPGUBXyVouWwMfANilWdkbQlsKzJMh+V9HpJhwKWdHBZ5t7AE80UaPujwCLgHOAY4JMUX/8OwFuajPMhSX9bxnYg8OeyrifpirlN0U7d0PLp2hUOJJ1r+/A21PNN22+bwOVtBdxg+znjLGcmxV/+iyXtBMwGbra9sBVxtoqkF1H8kXGV7Qdrjs+2/ZMmytuZotvtSeBo4L3APwJ3AO+y/T9Nxln7/fwbiu/nTc1+PyW9FDidIoEtB/7J9i2SpgFzbH+xmXKj9+y624AX/fLqhu7ZbKPJWeFgrOolHknvsP31RsscZhaWKPrUNyvrPLCT5Y1QJsD6g8ebLPMEYF9gHUk/oxjvugQ4VtKutj/VaJlVkPR+YB5wE/A1SUfZ/u/y9KeBhpOP7esoxlEGHVW+KLvJGk4+w3w/Z1K0hJr+ftq+vixn6PFV5aSTiEKXrHDQtS2feiT9oRwLavS+ayn+qjydYhxEFF0nhwM0OlDe6vLKMq8Bbmxxmb8CdgHWB/4ITLd9v6QNKVoYL220zCqUcb7C9oOSZgDfB75l+2RJ19pudnbaSPU1+3PU1u9ns3FGb9pt9wH/osGWz5QN0/IZM0nXj3QKaPaZj90p/ur9KPBh28skPTKO2VmtLg+KWWStLnON7SeAhyX9r+37AWw/IunJcZTbapMGu9ps/07SLIrB/e1octyjop+jln8/K4ozelUXtHy6NvlQ/A/3BuCeIcdFE10l8NTg7Rckfa/8958Yx/eo1eVVVSbwF0kb2X6YImECxYOcFGMhE8WfJO1iexlA2QI6ADgDaPbhzZb/HFHN97OKOKNHZW23ap0PbDz4i6iWpEXjKdj2CuBQSftTPCg5Lq0ur4Iy97L9WFlu7S/HdSkG3yeKtwFrag/YXgO8TVJTD5lSzc9RFd/Pyn7eo/dkzCciItpqt90HfPkVixu651nrT6o75lM+gnIyMBk43fZnhpxfH/gmRUv/buAw27+rV2dPPOcTERE1WriyqKTJwKkUMzh3AuaUj2PUOpLiwf8XAF+geN6yriSfiIge0+K13WYCt9q+zfZfgHOBg4ZccxDFg99QzEJ9zZAVSJ6hm8d8okdIegL4FcXP403AP5aD9c2UdSZwvu3vSzod+LztG0e4dhbwl0YfJJX0O4q15VaP5fiQax60PealmiR9HHjQ9n82EmP0r2uvWXrRRusVq6o3YANJS2o+z7c9v3y/NXB7zbkVFM8C1nrqGttrJN0HPAcY8f+FJJ+YCB6xvQuApLOB91Cshk15bJ1yYkFDbL9zlEtmUSwtlNli0TNszx79qs5Lt1tMNJcBL5A0S9Jl5coNN6rYa+k/VGx1cL2kdwOocIqkX0v6f8AWgwVJWiRpoHw/W8U2HNdJurh8SPU9wNGSlkl6laRpkn5Q1rFY5Z5Okp4j6acqtjM4nTE8RSHpR5KWlvfMHXLuC+Xxi8vlcZD0fEk/Ke+5TMUyQhETwR3ANjWfp5fHhr1G0jrAphQTD0aU5BMTRvlDuy9FFxzAbsBRtnekGNC8z/YewB7AuyRtD7wReCHFQOjbgFcOU+40ikVJ32R7Z+DQcibOaRR77exi+zLW7r2zB/AmilUkAE4ALrf9N8B5wFhWE/gn27tTPBT8AUmDa+89C1hSlvWLsmyA+cD7y3s+RPPbOUS02mJgB0nbq9jn63Bg6DJfC1j7GMEhwM89ylTqdLvFRLChpGXl+8uAr1Ekkatt/7Y8/nrgpZIOKT9vSrHI5l7AOeWKAndK+vkw5b8cuHSwLNt/HiGO1wI71YyTTlGxu+telNsW2L5A0tAHPYfzAUlvLN9vU8Z6N8VDpt8pj58F/LCs45XA92rqXn8MdURUrhzDmQdcRDHV+gzbyyWdSPGH1AKK/2e/JelWihXXR130OcknJoKnxnwGlb+EH6o9RNEyuGjIdfu1MI5JwMttPzpMLGNWTmR4LcU6dA+XD4GOtO2Fy3rvHfo9iJgoytXYFw45dnzN+0eBQxspM91u0S0uAt4raV0ASTtKehZwKXBYOSa0FfDqYe69Etir7KZD0rPL4w/w9J1Ffwq8f/CDpF3Kt5cCby6P7Uuxi249m1I88/BwOXbz8ppzkyi6JSjLvLxc++23KvYUGhzH2nmUOiK6WpJPdIvTKVbzvkbSDcBXKFru5wG/Kc99E7hi6I22VwFzKbq4rmNtt9ePgTcOTjgAPgAMlBMabqSYkADFttV7SVpO0f022m6kP6HYTuEm4DMUyW/QQ8DM8mvYBzixPP4W4MgyvuU88zmKiJ6S5XUiIqLt0vKJiIi2S/KJiIi2S/KJiIi2S/KJiIi2S/KJiIi2S/KJiIi2S/KJiIi2S/KJiIi2+/9WCUcH1rqEPAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.21      0.15        14\n",
      "           1       0.33      0.10      0.15        10\n",
      "           2       0.30      0.38      0.33         8\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.12      0.12      0.12        17\n",
      "           5       0.31      0.42      0.36        12\n",
      "           6       0.33      0.20      0.25        10\n",
      "           7       0.22      0.29      0.25        14\n",
      "           8       0.02      0.12      0.04         8\n",
      "           9       0.50      0.38      0.43        13\n",
      "          10       0.12      0.10      0.11        10\n",
      "          11       0.17      0.06      0.09        17\n",
      "          12       0.60      0.23      0.33        13\n",
      "          13       0.75      0.30      0.43        10\n",
      "          14       0.31      0.50      0.38         8\n",
      "          15       0.50      0.19      0.27        16\n",
      "          16       0.12      0.10      0.11        10\n",
      "          17       0.29      0.14      0.19        14\n",
      "          18       0.20      0.17      0.18        12\n",
      "          19       0.00      0.00      0.00        19\n",
      "          20       0.16      0.50      0.24        10\n",
      "          21       0.25      0.17      0.20        18\n",
      "          22       0.37      0.50      0.42        14\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.67      0.09      0.16        22\n",
      "          25       0.22      0.10      0.14        20\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.06      0.11      0.08         9\n",
      "          28       0.00      0.00      0.00        11\n",
      "          29       0.40      0.18      0.25        11\n",
      "          30       0.67      0.50      0.57         4\n",
      "          31       0.33      0.08      0.12        13\n",
      "          32       0.14      0.14      0.14         7\n",
      "          33       0.30      0.23      0.26        13\n",
      "          34       0.50      0.09      0.15        11\n",
      "          35       0.15      0.69      0.25        13\n",
      "          36       0.00      0.00      0.00        10\n",
      "          37       0.18      0.17      0.17        12\n",
      "          38       0.08      0.12      0.10         8\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.14      0.15      0.15        13\n",
      "          41       0.00      0.00      0.00         9\n",
      "          42       0.05      0.09      0.06        11\n",
      "          43       0.10      0.11      0.11         9\n",
      "          44       0.33      0.08      0.12        13\n",
      "          45       0.43      0.19      0.26        16\n",
      "          46       0.38      0.53      0.44        15\n",
      "          47       0.45      0.42      0.43        12\n",
      "          48       0.12      0.25      0.17         4\n",
      "          49       0.11      0.14      0.12         7\n",
      "\n",
      "    accuracy                           0.19       577\n",
      "   macro avg       0.24      0.19      0.19       577\n",
      "weighted avg       0.26      0.19      0.19       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_knn = gridKNN.predict(X_val)\n",
    "knn_f1 = metrics.f1_score(y_val, y_pred_knn, average= \"weighted\")\n",
    "knn_accuracy = metrics.accuracy_score(y_val, y_pred_knn)\n",
    "knn_cm = metrics.confusion_matrix(y_val[:10], y_pred_knn[:10])\n",
    "print(\"-----------------KNN Report---------------\")\n",
    "print(\"F1 score: {}\".format(knn_f1))\n",
    "print(\"Accuracy score: {}\".format(knn_accuracy))\n",
    "print(\"Confusion matrix for random 10 classes: \\n\", knn_cm)\n",
    "print('Plotting confusion matrix for random 10 classes')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(knn_cm[:10], y_val[:10])\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_val, y_pred_knn))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to ComplementNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-34-8219a56d1192>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mComplement_NB\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mComplementNB\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mComplement_NB\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mGaussian_NB\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGaussianNB\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    640\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_init_counters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_effective_classes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 641\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    642\u001B[0m         \u001B[0malpha\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_alpha\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    643\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_update_feature_log_prob\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\naive_bayes.py\u001B[0m in \u001B[0;36m_count\u001B[1;34m(self, X, Y)\u001B[0m\n\u001B[0;32m    868\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    869\u001B[0m         \u001B[1;34m\"\"\"Count feature occurrences.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 870\u001B[1;33m         \u001B[0mcheck_non_negative\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"ComplementNB (input X)\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    871\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_count_\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0msafe_sparse_dot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mY\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    872\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclass_count_\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_non_negative\u001B[1;34m(X, whom)\u001B[0m\n\u001B[0;32m   1044\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1045\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mX_min\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1046\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Negative values in data passed to %s\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mwhom\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1047\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1048\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Negative values in data passed to ComplementNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "if not is_reduce_dim:\n",
    "    Categorical_NB = CategoricalNB()\n",
    "    Categorical_NB.fit(X_train, y_train)\n",
    "\n",
    "    Complement_NB = ComplementNB()\n",
    "    Complement_NB.fit(X_train, y_train)\n",
    "\n",
    "    Gaussian_NB = GaussianNB()\n",
    "    Gaussian_NB.fit(X_train, y_train)\n",
    "\n",
    "    Multinomial_NB = MultinomialNB()\n",
    "    Multinomial_NB.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes Classifier report and analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Naive Bayes Classifier Report---------------\n",
      "CategoricalNB F1 score: 0.0007132835803298788 and Accuracy score: 0.019064124783362217\n",
      "ComplementNB F1 score: 0.19131295919341063 and Accuracy score: 0.22876949740034663\n",
      "GaussianNB F1 score: 0.23437753018737778 and Accuracy score: 0.24610051993067592\n",
      "MultinomialNB F1 score: 0.05428965555834216 and Accuracy score: 0.09532062391681109\n",
      "Confusion matrix for random 10 classes: \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]]\n",
      "Plotting confusion matrix for random 10 classes\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.29      0.30        14\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.14      0.12      0.13         8\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.08      0.06      0.07        17\n",
      "           5       0.50      0.42      0.45        12\n",
      "           6       0.17      0.20      0.18        10\n",
      "           7       0.17      0.21      0.19        14\n",
      "           8       0.33      0.38      0.35         8\n",
      "           9       0.21      0.23      0.22        13\n",
      "          10       0.25      0.10      0.14        10\n",
      "          11       0.25      0.18      0.21        17\n",
      "          12       0.36      0.38      0.37        13\n",
      "          13       0.33      0.50      0.40        10\n",
      "          14       0.17      0.50      0.26         8\n",
      "          15       0.86      0.38      0.52        16\n",
      "          16       0.62      0.50      0.56        10\n",
      "          17       0.00      0.00      0.00        14\n",
      "          18       0.20      0.08      0.12        12\n",
      "          19       0.00      0.00      0.00        19\n",
      "          20       0.27      0.40      0.32        10\n",
      "          21       0.17      0.06      0.08        18\n",
      "          22       0.56      0.71      0.63        14\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.40      0.18      0.25        22\n",
      "          25       0.33      0.30      0.32        20\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.12      0.11      0.12         9\n",
      "          28       0.40      0.18      0.25        11\n",
      "          29       0.57      0.36      0.44        11\n",
      "          30       0.10      0.25      0.14         4\n",
      "          31       0.18      0.15      0.17        13\n",
      "          32       0.50      0.14      0.22         7\n",
      "          33       0.26      0.77      0.39        13\n",
      "          34       0.06      0.09      0.07        11\n",
      "          35       0.43      0.46      0.44        13\n",
      "          36       0.20      0.20      0.20        10\n",
      "          37       0.25      0.25      0.25        12\n",
      "          38       0.25      0.12      0.17         8\n",
      "          39       0.67      0.18      0.29        11\n",
      "          40       0.20      0.23      0.21        13\n",
      "          41       0.10      0.11      0.11         9\n",
      "          42       0.00      0.00      0.00        11\n",
      "          43       0.18      0.56      0.27         9\n",
      "          44       0.00      0.00      0.00        13\n",
      "          45       0.44      0.25      0.32        16\n",
      "          46       0.31      0.33      0.32        15\n",
      "          47       0.24      0.50      0.32        12\n",
      "          48       0.09      0.25      0.13         4\n",
      "          49       0.21      0.57      0.31         7\n",
      "\n",
      "    accuracy                           0.25       577\n",
      "   macro avg       0.25      0.25      0.22       577\n",
      "weighted avg       0.27      0.25      0.23       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_Categorical_NB = Categorical_NB.predict(X_val)\n",
    "y_pred_Complement_NB = Complement_NB.predict(X_val)\n",
    "y_pred_Gaussian_NB = Gaussian_NB.predict(X_val)\n",
    "y_pred_Multinomial_NB = Multinomial_NB.predict(X_val)\n",
    "\n",
    "Categorical_NB_f1 = metrics.f1_score(y_val, y_pred_Categorical_NB, average= \"weighted\")\n",
    "Complement_NB_f1 = metrics.f1_score(y_val, y_pred_Complement_NB, average= \"weighted\")\n",
    "Gaussian_NB_f1 = metrics.f1_score(y_val, y_pred_Gaussian_NB, average= \"weighted\")\n",
    "Multinomial_NB_f1 = metrics.f1_score(y_val, y_pred_Multinomial_NB, average= \"weighted\")\n",
    "\n",
    "Categorical_NB_accuracy = metrics.accuracy_score(y_val, y_pred_Categorical_NB)\n",
    "Complement_NB_accuracy = metrics.accuracy_score(y_val, y_pred_Complement_NB)\n",
    "Gaussian_NB_accuracy = metrics.accuracy_score(y_val, y_pred_Gaussian_NB)\n",
    "Multinomial_NB_accuracy = metrics.accuracy_score(y_val, y_pred_Multinomial_NB)\n",
    "\n",
    "Gaussian_NB_cm = metrics.confusion_matrix(y_val[:10], y_pred_Gaussian_NB[:10])\n",
    "\n",
    "print(\"-----------------Naive Bayes Classifier Report---------------\")\n",
    "print(\"CategoricalNB F1 score: {} and Accuracy score: {}\".format(Categorical_NB_f1, Categorical_NB_accuracy))\n",
    "print(\"ComplementNB F1 score: {} and Accuracy score: {}\".format(Complement_NB_f1, Complement_NB_accuracy))\n",
    "print(\"GaussianNB F1 score: {} and Accuracy score: {}\".format(Gaussian_NB_f1, Gaussian_NB_accuracy))\n",
    "print(\"MultinomialNB F1 score: {} and Accuracy score: {}\".format(Multinomial_NB_f1, Multinomial_NB_accuracy))\n",
    "print(\"Confusion matrix for random 10 classes: \\n\", Gaussian_NB_cm)\n",
    "print('Plotting confusion matrix for random 10 classes')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(Gaussian_NB_cm[:10], y_val[:10])\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_val, y_pred_Gaussian_NB))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: poly kernel\n",
      "F1 score: 0.11290796480194293\n",
      "Accuracy score: 0.10745233968804159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.10        10\n",
      "   macro avg       0.08      0.08      0.08        10\n",
      "weighted avg       0.10      0.10      0.10        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: rbf kernel\n",
      "F1 score: 0.33746559903466355\n",
      "Accuracy score: 0.3587521663778163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       1.00      1.00      1.00         1\n",
      "          45       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.13      0.13      0.13        10\n",
      "weighted avg       0.20      0.20      0.20        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: sigmoid kernel\n",
      "F1 score: 0.309407901170187\n",
      "Accuracy score: 0.3223570190641248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       1.00      1.00      1.00         1\n",
      "          14       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         0\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       1.00      1.00      1.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       1.00      1.00      1.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.29      0.29      0.29        10\n",
      "weighted avg       0.40      0.40      0.40        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: linear kernel\n",
      "F1 score: 0.009059769575039818\n",
      "Accuracy score: 0.03119584055459272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       1.0\n",
      "          17       0.00      0.00      0.00       1.0\n",
      "          18       0.00      0.00      0.00       1.0\n",
      "          19       0.00      0.00      0.00       1.0\n",
      "          21       0.00      0.00      0.00       0.0\n",
      "          25       0.00      0.00      0.00       1.0\n",
      "          28       0.00      0.00      0.00       0.0\n",
      "          36       0.00      0.00      0.00       1.0\n",
      "          37       0.00      0.00      0.00       1.0\n",
      "          42       0.00      0.00      0.00       1.0\n",
      "          44       0.00      0.00      0.00       1.0\n",
      "          47       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00      10.0\n",
      "   macro avg       0.00      0.00      0.00      10.0\n",
      "weighted avg       0.00      0.00      0.00      10.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\zxcz1\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['poly', 'rbf', 'sigmoid','linear']\n",
    "for kernel in kernels:\n",
    "    svc = SVC(kernel=kernel)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_val)\n",
    "    svc_f1 = metrics.f1_score(y_val, y_pred, average= \"weighted\")\n",
    "    print(\"Evaluation:\", kernel, \"kernel\")\n",
    "    print(\"F1 score: {}\".format(svc_f1))\n",
    "    svc_accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    print(\"Accuracy score: {}\".format(svc_accuracy))\n",
    "    print(metrics.classification_report(y_val[:10],y_pred[:10]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed:   45.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3441884372347449\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVC(C=10)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': ['scale', 'auto'],'kernel': kernels[:2]}\n",
    "svc = SVC()\n",
    "grid_svc = GridSearchCV(svc, param_grid, refit=True, verbose=2, n_jobs=4)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print(grid_svc.best_score_)\n",
    "print(grid_svc.best_params_)\n",
    "print(grid_svc.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Classifier report and analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------SVM Classifier Report---------------\n",
      "F1 score: 0.372472746369572\n",
      "Accuracy score: 0.38128249566724437\n",
      "Confusion matrix for random 10 classes: \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Plotting confusion matrix for random 10 classes\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.21      0.22        14\n",
      "           1       0.09      0.10      0.10        10\n",
      "           2       0.27      0.38      0.32         8\n",
      "           3       0.25      0.67      0.36         3\n",
      "           4       0.17      0.12      0.14        17\n",
      "           5       0.47      0.67      0.55        12\n",
      "           6       0.37      0.70      0.48        10\n",
      "           7       0.39      0.50      0.44        14\n",
      "           8       0.27      0.38      0.32         8\n",
      "           9       0.45      0.38      0.42        13\n",
      "          10       0.38      0.30      0.33        10\n",
      "          11       0.40      0.47      0.43        17\n",
      "          12       0.35      0.46      0.40        13\n",
      "          13       0.42      0.50      0.45        10\n",
      "          14       0.45      0.62      0.53         8\n",
      "          15       0.77      0.62      0.69        16\n",
      "          16       0.53      0.80      0.64        10\n",
      "          17       0.67      0.29      0.40        14\n",
      "          18       0.27      0.33      0.30        12\n",
      "          19       0.29      0.11      0.15        19\n",
      "          20       0.31      0.40      0.35        10\n",
      "          21       0.28      0.28      0.28        18\n",
      "          22       0.85      0.79      0.81        14\n",
      "          23       0.12      0.08      0.10        12\n",
      "          24       0.67      0.18      0.29        22\n",
      "          25       0.38      0.45      0.41        20\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.27      0.33      0.30         9\n",
      "          28       0.22      0.45      0.29        11\n",
      "          29       0.73      0.73      0.73        11\n",
      "          30       0.17      0.25      0.20         4\n",
      "          31       0.50      0.38      0.43        13\n",
      "          32       0.50      0.14      0.22         7\n",
      "          33       0.46      0.46      0.46        13\n",
      "          34       0.50      0.09      0.15        11\n",
      "          35       0.62      0.62      0.62        13\n",
      "          36       0.50      0.30      0.37        10\n",
      "          37       0.40      0.33      0.36        12\n",
      "          38       0.50      0.38      0.43         8\n",
      "          39       0.50      0.09      0.15        11\n",
      "          40       0.50      0.38      0.43        13\n",
      "          41       0.33      0.22      0.27         9\n",
      "          42       0.12      0.09      0.11        11\n",
      "          43       0.12      0.22      0.16         9\n",
      "          44       0.56      0.38      0.45        13\n",
      "          45       0.24      0.50      0.32        16\n",
      "          46       0.53      0.67      0.59        15\n",
      "          47       0.60      0.50      0.55        12\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.22      0.29      0.25         7\n",
      "\n",
      "    accuracy                           0.38       577\n",
      "   macro avg       0.38      0.37      0.36       577\n",
      "weighted avg       0.41      0.38      0.37       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_svc = grid_svc.predict(X_val)\n",
    "svc_f1 = metrics.f1_score(y_val, y_pred_svc, average= \"weighted\")\n",
    "svc_accuracy = metrics.accuracy_score(y_val, y_pred_svc)\n",
    "svc_cm = metrics.confusion_matrix(y_val[:10], y_pred_svc[:10])\n",
    "print(\"-----------------SVM Classifier Report---------------\")\n",
    "print(\"F1 score: {}\".format(svc_f1))\n",
    "print(\"Accuracy score: {}\".format(svc_accuracy))\n",
    "print(\"Confusion matrix for random 10 classes: \\n\", svc_cm)\n",
    "print('Plotting confusion matrix for random 10 classes')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(svc_cm[:10], y_val[:10])\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_val, y_pred_svc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.91851740\n",
      "Iteration 2, loss = 3.90668161\n",
      "Iteration 3, loss = 3.89493631\n",
      "Iteration 4, loss = 3.87659171\n",
      "Iteration 5, loss = 3.84345641\n",
      "Iteration 6, loss = 3.78277609\n",
      "Iteration 7, loss = 3.68657792\n",
      "Iteration 8, loss = 3.56533681\n",
      "Iteration 9, loss = 3.44133515\n",
      "Iteration 10, loss = 3.32320171\n",
      "Iteration 11, loss = 3.21317001\n",
      "Iteration 12, loss = 3.11151858\n",
      "Iteration 13, loss = 3.02804539\n",
      "Iteration 14, loss = 2.95906798\n",
      "Iteration 15, loss = 2.88374073\n",
      "Iteration 16, loss = 2.81685173\n",
      "Iteration 17, loss = 2.75176799\n",
      "Iteration 18, loss = 2.69673035\n",
      "Iteration 19, loss = 2.66375226\n",
      "Iteration 20, loss = 2.62564347\n",
      "Iteration 21, loss = 2.58992327\n",
      "Iteration 22, loss = 2.54574885\n",
      "Iteration 23, loss = 2.52014356\n",
      "Iteration 24, loss = 2.49599454\n",
      "Iteration 25, loss = 2.46306056\n",
      "Iteration 26, loss = 2.43552794\n",
      "Iteration 27, loss = 2.40927351\n",
      "Iteration 28, loss = 2.38796950\n",
      "Iteration 29, loss = 2.36850509\n",
      "Iteration 30, loss = 2.33187247\n",
      "Iteration 31, loss = 2.30099040\n",
      "Iteration 32, loss = 2.27848758\n",
      "Iteration 33, loss = 2.26442234\n",
      "Iteration 34, loss = 2.23215878\n",
      "Iteration 35, loss = 2.20503429\n",
      "Iteration 36, loss = 2.17608827\n",
      "Iteration 37, loss = 2.16397613\n",
      "Iteration 38, loss = 2.13464526\n",
      "Iteration 39, loss = 2.11238480\n",
      "Iteration 40, loss = 2.09382760\n",
      "Iteration 41, loss = 2.06055713\n",
      "Iteration 42, loss = 2.03533052\n",
      "Iteration 43, loss = 2.01634363\n",
      "Iteration 44, loss = 1.99477699\n",
      "Iteration 45, loss = 1.97365766\n",
      "Iteration 46, loss = 1.94656359\n",
      "Iteration 47, loss = 1.92130820\n",
      "Iteration 48, loss = 1.89436742\n",
      "Iteration 49, loss = 1.87927818\n",
      "Iteration 50, loss = 1.86086121\n",
      "Iteration 51, loss = 1.83018620\n",
      "Iteration 52, loss = 1.80174663\n",
      "Iteration 53, loss = 1.78659758\n",
      "Iteration 54, loss = 1.76143990\n",
      "Iteration 55, loss = 1.73326698\n",
      "Iteration 56, loss = 1.72554913\n",
      "Iteration 57, loss = 1.69489366\n",
      "Iteration 58, loss = 1.67409078\n",
      "Iteration 59, loss = 1.63642619\n",
      "Iteration 60, loss = 1.61413380\n",
      "Iteration 61, loss = 1.58886319\n",
      "Iteration 62, loss = 1.55829160\n",
      "Iteration 63, loss = 1.54583162\n",
      "Iteration 64, loss = 1.52885511\n",
      "Iteration 65, loss = 1.50001715\n",
      "Iteration 66, loss = 1.46730292\n",
      "Iteration 67, loss = 1.44675279\n",
      "Iteration 68, loss = 1.42299057\n",
      "Iteration 69, loss = 1.39646855\n",
      "Iteration 70, loss = 1.37439908\n",
      "Iteration 71, loss = 1.34230166\n",
      "Iteration 72, loss = 1.32143405\n",
      "Iteration 73, loss = 1.29723346\n",
      "Iteration 74, loss = 1.27188635\n",
      "Iteration 75, loss = 1.24687084\n",
      "Iteration 76, loss = 1.21940786\n",
      "Iteration 77, loss = 1.20327902\n",
      "Iteration 78, loss = 1.18328247\n",
      "Iteration 79, loss = 1.14737150\n",
      "Iteration 80, loss = 1.12348123\n",
      "Iteration 81, loss = 1.10810870\n",
      "Iteration 82, loss = 1.08007301\n",
      "Iteration 83, loss = 1.05624158\n",
      "Iteration 84, loss = 1.02542061\n",
      "Iteration 85, loss = 1.00843556\n",
      "Iteration 86, loss = 0.98962059\n",
      "Iteration 87, loss = 0.96717503\n",
      "Iteration 88, loss = 0.94296246\n",
      "Iteration 89, loss = 0.91919038\n",
      "Iteration 90, loss = 0.88607839\n",
      "Iteration 91, loss = 0.86458283\n",
      "Iteration 92, loss = 0.84130421\n",
      "Iteration 93, loss = 0.81867961\n",
      "Iteration 94, loss = 0.79964326\n",
      "Iteration 95, loss = 0.77907805\n",
      "Iteration 96, loss = 0.75999181\n",
      "Iteration 97, loss = 0.73357610\n",
      "Iteration 98, loss = 0.71851507\n",
      "Iteration 99, loss = 0.70210915\n",
      "Iteration 100, loss = 0.68064312\n",
      "Iteration 101, loss = 0.65917303\n",
      "Iteration 102, loss = 0.63889592\n",
      "Iteration 103, loss = 0.61982370\n",
      "Iteration 104, loss = 0.60253227\n",
      "Iteration 105, loss = 0.57898894\n",
      "Iteration 106, loss = 0.56317769\n",
      "Iteration 107, loss = 0.54555982\n",
      "Iteration 108, loss = 0.52391139\n",
      "Iteration 109, loss = 0.50725630\n",
      "Iteration 110, loss = 0.49290670\n",
      "Iteration 111, loss = 0.47796278\n",
      "Iteration 112, loss = 0.46139305\n",
      "Iteration 113, loss = 0.44790101\n",
      "Iteration 114, loss = 0.43317408\n",
      "Iteration 115, loss = 0.41750036\n",
      "Iteration 116, loss = 0.39887390\n",
      "Iteration 117, loss = 0.38663389\n",
      "Iteration 118, loss = 0.36898066\n",
      "Iteration 119, loss = 0.35848018\n",
      "Iteration 120, loss = 0.34393541\n",
      "Iteration 121, loss = 0.33372074\n",
      "Iteration 122, loss = 0.32605176\n",
      "Iteration 123, loss = 0.30668091\n",
      "Iteration 124, loss = 0.29090912\n",
      "Iteration 125, loss = 0.28152578\n",
      "Iteration 126, loss = 0.27267813\n",
      "Iteration 127, loss = 0.26181484\n",
      "Iteration 128, loss = 0.25593538\n",
      "Iteration 129, loss = 0.24819569\n",
      "Iteration 130, loss = 0.23386956\n",
      "Iteration 131, loss = 0.22422650\n",
      "Iteration 132, loss = 0.21667258\n",
      "Iteration 133, loss = 0.21184384\n",
      "Iteration 134, loss = 0.20153628\n",
      "Iteration 135, loss = 0.19449827\n",
      "Iteration 136, loss = 0.18588293\n",
      "Iteration 137, loss = 0.17584087\n",
      "Iteration 138, loss = 0.17128258\n",
      "Iteration 139, loss = 0.16458080\n",
      "Iteration 140, loss = 0.15801842\n",
      "Iteration 141, loss = 0.15229807\n",
      "Iteration 142, loss = 0.14778251\n",
      "Iteration 143, loss = 0.14226070\n",
      "Iteration 144, loss = 0.13837015\n",
      "Iteration 145, loss = 0.13309746\n",
      "Iteration 146, loss = 0.12857940\n",
      "Iteration 147, loss = 0.12256538\n",
      "Iteration 148, loss = 0.11825282\n",
      "Iteration 149, loss = 0.11222322\n",
      "Iteration 150, loss = 0.10900589\n",
      "Iteration 151, loss = 0.10564925\n",
      "Iteration 152, loss = 0.10206719\n",
      "Iteration 153, loss = 0.09830212\n",
      "Iteration 154, loss = 0.09514313\n",
      "Iteration 155, loss = 0.09185427\n",
      "Iteration 156, loss = 0.08849832\n",
      "Iteration 157, loss = 0.08563695\n",
      "Iteration 158, loss = 0.08239070\n",
      "Iteration 159, loss = 0.07843293\n",
      "Iteration 160, loss = 0.07643068\n",
      "Iteration 161, loss = 0.07443519\n",
      "Iteration 162, loss = 0.07163602\n",
      "Iteration 163, loss = 0.06963540\n",
      "Iteration 164, loss = 0.06770421\n",
      "Iteration 165, loss = 0.06498956\n",
      "Iteration 166, loss = 0.06362826\n",
      "Iteration 167, loss = 0.06145812\n",
      "Iteration 168, loss = 0.05925235\n",
      "Iteration 169, loss = 0.05825801\n",
      "Iteration 170, loss = 0.05585520\n",
      "Iteration 171, loss = 0.05410136\n",
      "Iteration 172, loss = 0.05349146\n",
      "Iteration 173, loss = 0.05147667\n",
      "Iteration 174, loss = 0.04986412\n",
      "Iteration 175, loss = 0.04842714\n",
      "Iteration 176, loss = 0.04681001\n",
      "Iteration 177, loss = 0.04544163\n",
      "Iteration 178, loss = 0.04428745\n",
      "Iteration 179, loss = 0.04314683\n",
      "Iteration 180, loss = 0.04180556\n",
      "Iteration 181, loss = 0.04112993\n",
      "Iteration 182, loss = 0.03991684\n",
      "Iteration 183, loss = 0.03888914\n",
      "Iteration 184, loss = 0.03794878\n",
      "Iteration 185, loss = 0.03685872\n",
      "Iteration 186, loss = 0.03614467\n",
      "Iteration 187, loss = 0.03563612\n",
      "Iteration 188, loss = 0.03426878\n",
      "Iteration 189, loss = 0.03356134\n",
      "Iteration 190, loss = 0.03243206\n",
      "Iteration 191, loss = 0.03181896\n",
      "Iteration 192, loss = 0.03147660\n",
      "Iteration 193, loss = 0.03071394\n",
      "Iteration 194, loss = 0.02976843\n",
      "Iteration 195, loss = 0.02911032\n",
      "Iteration 196, loss = 0.02856925\n",
      "Iteration 197, loss = 0.02800005\n",
      "Iteration 198, loss = 0.02703971\n",
      "Iteration 199, loss = 0.02648496\n",
      "Iteration 200, loss = 0.02592348\n",
      "Iteration 201, loss = 0.02559939\n",
      "Iteration 202, loss = 0.02530143\n",
      "Iteration 203, loss = 0.02441561\n",
      "Iteration 204, loss = 0.02401991\n",
      "Iteration 205, loss = 0.02327111\n",
      "Iteration 206, loss = 0.02294512\n",
      "Iteration 207, loss = 0.02226079\n",
      "Iteration 208, loss = 0.02196584\n",
      "Iteration 209, loss = 0.02149158\n",
      "Iteration 210, loss = 0.02113766\n",
      "Iteration 211, loss = 0.02053283\n",
      "Iteration 212, loss = 0.02022995\n",
      "Iteration 213, loss = 0.01976390\n",
      "Iteration 214, loss = 0.01966140\n",
      "Iteration 215, loss = 0.01904467\n",
      "Iteration 216, loss = 0.01870182\n",
      "Iteration 217, loss = 0.01853014\n",
      "Iteration 218, loss = 0.01818719\n",
      "Iteration 219, loss = 0.01778577\n",
      "Iteration 220, loss = 0.01743997\n",
      "Iteration 221, loss = 0.01720392\n",
      "Iteration 222, loss = 0.01689717\n",
      "Iteration 223, loss = 0.01645507\n",
      "Iteration 224, loss = 0.01631703\n",
      "Iteration 225, loss = 0.01590579\n",
      "Iteration 226, loss = 0.01564938\n",
      "Iteration 227, loss = 0.01544097\n",
      "Iteration 228, loss = 0.01520593\n",
      "Iteration 229, loss = 0.01500786\n",
      "Iteration 230, loss = 0.01467207\n",
      "Iteration 231, loss = 0.01449363\n",
      "Iteration 232, loss = 0.01424014\n",
      "Iteration 233, loss = 0.01403066\n",
      "Iteration 234, loss = 0.01377917\n",
      "Iteration 235, loss = 0.01351051\n",
      "Iteration 236, loss = 0.01337623\n",
      "Iteration 237, loss = 0.01315203\n",
      "Iteration 238, loss = 0.01299001\n",
      "Iteration 239, loss = 0.01277081\n",
      "Iteration 240, loss = 0.01259514\n",
      "Iteration 241, loss = 0.01238442\n",
      "Iteration 242, loss = 0.01221362\n",
      "Iteration 243, loss = 0.01217685\n",
      "Iteration 244, loss = 0.01181829\n",
      "Iteration 245, loss = 0.01166968\n",
      "Iteration 246, loss = 0.01155553\n",
      "Iteration 247, loss = 0.01135399\n",
      "Iteration 248, loss = 0.01119511\n",
      "Iteration 249, loss = 0.01103087\n",
      "Iteration 250, loss = 0.01087275\n",
      "Iteration 251, loss = 0.01076689\n",
      "Iteration 252, loss = 0.01057375\n",
      "Iteration 253, loss = 0.01048190\n",
      "Iteration 254, loss = 0.01032723\n",
      "Iteration 255, loss = 0.01020132\n",
      "Iteration 256, loss = 0.01004546\n",
      "Iteration 257, loss = 0.00992177\n",
      "Iteration 258, loss = 0.00981075\n",
      "Iteration 259, loss = 0.00970664\n",
      "Iteration 260, loss = 0.00955742\n",
      "Iteration 261, loss = 0.00945293\n",
      "Iteration 262, loss = 0.00935453\n",
      "Iteration 263, loss = 0.00921760\n",
      "Iteration 264, loss = 0.00911070\n",
      "Iteration 265, loss = 0.00902011\n",
      "Iteration 266, loss = 0.00888203\n",
      "Iteration 267, loss = 0.00880909\n",
      "Iteration 268, loss = 0.00874015\n",
      "Iteration 269, loss = 0.00858316\n",
      "Iteration 270, loss = 0.00853963\n",
      "Iteration 271, loss = 0.00839991\n",
      "Iteration 272, loss = 0.00830232\n",
      "Iteration 273, loss = 0.00827682\n",
      "Iteration 274, loss = 0.00820319\n",
      "Iteration 275, loss = 0.00806464\n",
      "Iteration 276, loss = 0.00796805\n",
      "Iteration 277, loss = 0.00788756\n",
      "Iteration 278, loss = 0.00780847\n",
      "Iteration 279, loss = 0.00771497\n",
      "Iteration 280, loss = 0.00764427\n",
      "Iteration 281, loss = 0.00753503\n",
      "Iteration 282, loss = 0.00748583\n",
      "Iteration 283, loss = 0.00739487\n",
      "Iteration 284, loss = 0.00733731\n",
      "Iteration 285, loss = 0.00727189\n",
      "Iteration 286, loss = 0.00718990\n",
      "Iteration 287, loss = 0.00709848\n",
      "Iteration 288, loss = 0.00704416\n",
      "Iteration 289, loss = 0.00701746\n",
      "Iteration 290, loss = 0.00691460\n",
      "Iteration 291, loss = 0.00684914\n",
      "Iteration 292, loss = 0.00680259\n",
      "Iteration 293, loss = 0.00674233\n",
      "Iteration 294, loss = 0.00667824\n",
      "Iteration 295, loss = 0.00664979\n",
      "Iteration 296, loss = 0.00657149\n",
      "Iteration 297, loss = 0.00653154\n",
      "Iteration 298, loss = 0.00647010\n",
      "Iteration 299, loss = 0.00638084\n",
      "Iteration 300, loss = 0.00633729\n",
      "Iteration 301, loss = 0.00628436\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": "MLPClassifier(hidden_layer_sizes=(512, 512, 64), max_iter=500, verbose=2)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512, 512, 64), verbose=2, max_iter=500)\n",
    "clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP Classifier report and analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------MLP Classifier Report---------------\n",
      "F1 score: 0.2535845676284849\n",
      "Accuracy score: 0.24783362218370883\n",
      "Confusion matrix for random 10 classes: \n",
      " [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "Plotting confusion matrix for random 10 classes\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29        14\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.38      0.38      0.38         8\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.29      0.12      0.17        17\n",
      "           5       0.33      0.25      0.29        12\n",
      "           6       0.36      0.50      0.42        10\n",
      "           7       0.27      0.29      0.28        14\n",
      "           8       0.25      0.25      0.25         8\n",
      "           9       0.29      0.15      0.20        13\n",
      "          10       0.08      0.10      0.09        10\n",
      "          11       0.42      0.29      0.34        17\n",
      "          12       0.36      0.31      0.33        13\n",
      "          13       0.25      0.30      0.27        10\n",
      "          14       0.25      0.38      0.30         8\n",
      "          15       0.71      0.31      0.43        16\n",
      "          16       0.42      0.50      0.45        10\n",
      "          17       0.33      0.29      0.31        14\n",
      "          18       0.25      0.17      0.20        12\n",
      "          19       0.20      0.16      0.18        19\n",
      "          20       0.27      0.40      0.32        10\n",
      "          21       0.19      0.22      0.21        18\n",
      "          22       0.56      0.64      0.60        14\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.29      0.18      0.22        22\n",
      "          25       0.32      0.35      0.33        20\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.07      0.11      0.09         9\n",
      "          28       0.19      0.27      0.22        11\n",
      "          29       0.50      0.73      0.59        11\n",
      "          30       0.43      0.75      0.55         4\n",
      "          31       0.17      0.08      0.11        13\n",
      "          32       0.11      0.14      0.12         7\n",
      "          33       0.25      0.23      0.24        13\n",
      "          34       0.08      0.09      0.08        11\n",
      "          35       0.27      0.23      0.25        13\n",
      "          36       0.29      0.20      0.24        10\n",
      "          37       0.18      0.17      0.17        12\n",
      "          38       0.22      0.25      0.24         8\n",
      "          39       0.27      0.27      0.27        11\n",
      "          40       0.29      0.31      0.30        13\n",
      "          41       0.00      0.00      0.00         9\n",
      "          42       0.20      0.18      0.19        11\n",
      "          43       0.22      0.22      0.22         9\n",
      "          44       0.60      0.23      0.33        13\n",
      "          45       0.20      0.19      0.19        16\n",
      "          46       0.36      0.27      0.31        15\n",
      "          47       0.57      0.33      0.42        12\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.25       577\n",
      "   macro avg       0.26      0.24      0.24       577\n",
      "weighted avg       0.28      0.25      0.25       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp = clf.predict(X_val)\n",
    "mlp_f1 = metrics.f1_score(y_val, y_pred_mlp, average= \"weighted\")\n",
    "mlp_accuracy = metrics.accuracy_score(y_val, y_pred_mlp)\n",
    "mlp_cm = metrics.confusion_matrix(y_val[:10], y_pred_mlp[:10])\n",
    "print(\"-----------------MLP Classifier Report---------------\")\n",
    "print(\"F1 score: {}\".format(mlp_f1))\n",
    "print(\"Accuracy score: {}\".format(mlp_accuracy))\n",
    "print(\"Confusion matrix for random 10 classes: \\n\", mlp_cm)\n",
    "print('Plotting confusion matrix for random 10 classes')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(mlp_cm[:10], y_val[:10])\n",
    "plt.show()\n",
    "\n",
    "print(metrics.classification_report(y_val, y_pred_mlp))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}